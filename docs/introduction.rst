Introduction
============

There are multiple ways to carry out VASP calculations.

The somewhat "primitive" way is creating a directory, writing up or copying from somewhere else the input files, mostly INCAR, KPOINTS, POSCAR, POTCAR, and a job submission file depending on the supercomputer one is using, then submiting the job and waiting for the output files showing up in the same directory. 

But most of the time, one single run is far from enough to extract the information one wishes to obtain. Rather, a series of runs with one or more varying parameters are needed, a post-analysis should be done, and a cumulative but terse output in the form of a file or direct screen output should be provided to the user. Examples are **cut-off energy and k-points convergence tests**, **lattice constant (equilibrium volume) and bulk modulus test**, **elastic constant test**, and some **exotic tests** that require a **gradual change** somewhere in the **POSCAR**, such as a **rotation of several chosen ions**. No one should expect a user to have the patience to change the varying parameter of every single run in the series and submit them one by one, extract information from each run by hand, finally fit the curve, conclude the coefficients and preferably plot them in a saved figure. In order to tackle this problem, there are two automated ways.

The **first** is wrapping up the job preparation, execution and post-analysis trilogy in an installable package, written in and for a high level scripting language, such as Python. A famous example is [ASE] (https://wiki.fysik.dtu.dk/ase/) (Atomic Simulation Environment). One needs to install the Python package and read the documentation on the location and functionality of their defined classes and methods, write up a Python script for a series of runs, oftentimes along with the post-analysis part and feed it to the batch job submission script. It has a lot of advantages, especially if one deals with different kinds of _ab initio_ calculators and very routine work that all of them share, because it hides the basic file and directory manipulation, which are different for different calculators, and let users work with its defined Python classes and methods.

The **second** is providing a collection of scripts, written in a shell scripting language, like Bash, and accompanying them with scripts written in a programming scripting language, like Python, in the same directory, with careful use of file names and input arguments, and letting users add this single directory into their PATH environmental variable to have direct access. The scripts will be used as executables. This project aims to strengthen such an approach. This approach is less systematic than the former, but it also has some obvious advantages comparitively.

* It provides more flexibility in terms of file and directory manipulation, because Bash, as a shell language, deals with them more natively than Python, if one doesn't bother to use more Python packages in order to replace Bash. The directory that ASE runs in will not hold the full output of a series of runs, but only the last one, in an **equilibrium volume and bulk modulus** routine. But with Bash one can conveniently create subdirectories to hold the input and output of each run in an automated way, thus keeping records of everything for future use.

* With all of the output files present, one can do far more checks and data collection with some knowledge of command line tools such as **cat**, **grep**, **sed**, **awk**, and **find**. These tools are considered more universal than the layered classes and methods defined in ASE Python package. The executable scripts in a single directory are grouped more straighforwardly, showing the users only task related commands with simple keywords. As far as my own experience, VASP is already a delicate machine that requires enough memorization of its tags, and through reading the docs on them written by the VASP creators, I automatically get the idea of where to look for the desired information in the output files. There is really less motivation to learn a completely new Pythonic scheme. Plus, if the physics I'm looking at needs custom expression and control than standard methods provided by a Python package, I'm more likely to express it myself with **grep**, **sed** and **awk**, than wait for the developers of ASE to come up with a new method and a new code block somewhere in their documentation. At least, at this stage in my opinion, there are more physics than the convenient expression of Python classes and methods.

* One can freely separate processes of the input files preparation, job submission and post-analysis, just as implemented in this project by **Prepare.sh**, **Fire.sh**, and **Display.sh**, or combine the first two for daily use when feeling secure as **Prep-fire.sh**. For a single run, one can just use **Fast-prep.sh**. The overall directory structure will be very neat. This opens a door widely to runs that depend on the output of previous runs. It's just several lines of commands away with all the convenient tools in the linux shell.

* If one writes up a Python script describing a series of runs with ASE, and submit the whole thing, and it reaches the walltime, or one or more of the runs crash, or the script is faulty somewhere, which are scenarios that always happen, the script cannot be finished, and it would be difficult to pick up what has been terminated unexpectedly. The scheme is somewhat fragile. With the existence of multiple subdirectories, however, one can give each run in a series an independent job submission script, and submit them selectively. If one run reaches the walltime or simply fails, one can easily identify it, change the input parameter and submit it again, and other runs won't be affected. If there are mistakes in the job preparation scripts, one will discover them before submission, because chances are that those mistakes are directly output on the screen before one fire up the submission scripts.


* To save more space, one can choose not to output, or just delete the WAVECAR, CHG, and CHGCAR, which are disk space eaters.

Based on above reasons, which of course will be less persuasive for an experience ASE user who is already familiar with its Pythonic scheme and capable of freely manipulating directories anyway, or if ASE improves its management of directories, I present the following scripts that are used by me on a daily basis for dealing with routines described in the beginning of this section, and scripts offering more functionalities, including the usual need for **density of states plots**, **band structure plots**, **Bader charge transfer analysis**, etc. The list will go on and can be mixed with other people's scripts conveniently.

Due to the low level of "abstraction", it is assumed that the user of this script collection is familiar with simple Bash syntax, command line tools such as **cat**, **grep**, **sed**, **awk**, **find** and some Python. Flexibility comes with some price, so one may need to look at the codes and change some lines. But since one doesn't have to be forced to face a formidable Python package with intricate definitions, it will be much easier. I'll try to turn the hard coded parts to automated detection and sweet input command line arguments, and make appropriate comments on the routines as I progress. This is still an ongoing project, but you are welcome to fork it and modify the scripts to your own need.

